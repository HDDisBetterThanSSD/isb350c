Describe your implementation:

What worked?

What didn't work?

What did you learn?

-------------

The ISB is a prefetcher designed by Akanksha Jain and Calvin Lin. It is
described in their MICRO13 paper "Linearizing Irregular Memory Accesses for
Improved Correlated Prefetching". I will give a short explaination of the design
here, followed by an explanation of my design choices.

About the ISB
=============

PC localization and Address Correlation
---------------------------------------
The ISB is the first design, according to Jain and Lin, that combines PC
localizataion with address correlation efficiently. The term "PC localization"
means that streams are distinguished from each other based on the PC of the
memory access. The "address correlation" refers to the technique of identifying
temporal streams (as opposed to spatial stream).

Many previous designs that attempt to achieve this combination use the GHB, as
described by Nesbit and Smith. While, the GHB has proved a useful generic data
structure for prefetching in the literature, it would be inefficient at PC
localization, since it would require following a linked list off-chip (where the
GHB lives).

Jain and Lin's design keeps relavent metadata on-chip for fast access, as
discussed below.

Structural Addresses
--------------------
The ISB is designed to handle irregular data streams. It works by mapping
temporally correlated addresses in the physical address space to consecutive
addresses in an internal "structural address space". Structural addresses are a
construct of the prefetcher. In the structural address space, temporally
correlated physical addresses are also spatially correlated. Then, a simple
regular stream prefetcher can act on the structural address space with high
accuracy. The resulting prefetch candidates in the structural address space are
translated back into physical addresses and requested from memory.

TLB Syncing
-----------
Jain and Lin describe a technique for hiding the latency of accessing off-chip
metadata. Metadata for the current memory page is kept on chip for the
prefetcher's use. When a TLB eviction occurs, the prefetcher swaps metadata for
the evicted page with metadata for the incoming page. Since TLB evictions are
notoriously slow, the prefetcher's latency is mostly hidden.

Components
----------
The ISB has four main components.

1. Physical->Structural Address Map Cache (PSAMC): This data structure stores
the mapping from physical addresses to structural addresses.

2. Structural->Physical Address Map Cache (PSAMC): This data structure stores
the reverse mapping (back to physical addresses). It is not strictly neccessary,
but it allows fast address translation.

3. Training Unit: This component finds pairs of temporally correlated addresses
based on the PC and maps them to consecutive structural addresses.

4. Steam Predictor: This component is a stream buffer that acts on structural
addresses.


My implementation
=================

Simplifications
---------------
My processor has many unrealistic simplifications that allowed me to finish the
project in a more timely manner. Nonetheless, I did try to keep the main
components of the original ISB and follow the original algorithms as closely as
possible.

1. No store instruction: this is a bit disatisfying to me, but it greatly
simplifies life. Additionally, the prefetcher only has to predict data reads.

2. No virtual memory: one implication of this simplification is that there is no
TLB, so TLB syncing was not implemented.

3. No off-chip storage: since the test programs are very small, I decided not to
use any off-chip storage at all.

4. Small structural address space: In Jain and Lin's design, the size of on-chip
storage is not a limitation, since data can be written to the off-chip storage.
However, since my design does not have off-chip storage, I limit the structural
address space to 32 addresses. When these addresses are used up, the prefetcher
stops training. I could have used an LRU policy to throw out the LRU stream, but
time was short. This is also a bit dissatisfying, but I believe it is enough to
demonstrate the functionality of the prefetcher.

Specs
-----
My implementation has the following specs
* Max steam length: 16 addrs
* PS-AMC size: 32 entries mapping 1 PA each
* SP-AMC size: 8 entries mapping 4 PAs each
* Training unit: 4 entries
* Steam predictor: a stream buffer with a queue of 4 entries, degree 1

Problems encountered
--------------------
* I had some difficulty deciding how to adapt the ISB design to my very
  simplified processor. I think in the end, my design choices allowed me to
demonstrate the prefetcher well.

* Memory traffic: My design has only one memory port for use by the LD unit
  (core traffic) and the prefetcher (non-critical traffic). Thus, prefetcher
traffic often caused core traffic to slow down. This is a well-known phenomenon
in real prefetchers, as well, but it is greatly exaggerated in my design.
